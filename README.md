<!-- ðŸ§  Ollama LLM Practice Project -->

This project demonstrates how to use Ollama with Python to:
ðŸ“‚ Read grocery data from a file
ðŸ¤– Categorize and sort items using LLaMA 3.2
ðŸ’¬ Perform chat-based queries
ðŸŒŠ Create and use custom models
âš¡ Stream AI responses in real time

<!-- ðŸš€ Technologies Used -->

Python 3.x
Ollama
LLaMA 3.2 model

<!-- ðŸ“ Project Structure -->

Ollama-2/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ grocery.txt
â”‚ â””â”€â”€ order_grocery.txt
â”‚
â”œâ”€â”€ file1.py # Grocery categorization
â”œâ”€â”€ file2.py # Streaming + chat examples
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
